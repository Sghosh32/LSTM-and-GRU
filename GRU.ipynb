{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GRU",
      "provenance": [],
      "authorship_tag": "ABX9TyPSVIokbN6RJ6ZtPYjDUVz8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sghosh32/LSTM-and-GRU/blob/main/GRU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XB-i8Drh-38m"
      },
      "outputs": [],
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot  as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = open('dinosaurs.csv', 'r').read() \n",
        "data = data.lower()\n",
        "chars = list(set(data))\n",
        "chars.remove('\\n')\n",
        "chars.sort()\n",
        "print(chars)\n",
        "data_size, chars_size = len(data), len(chars)\n",
        "\n",
        "print(\"data size= \" ,data_size)\n",
        "print(\"no of unique chars = \" ,chars_size)\n",
        "\n",
        "char_to_ix = {ch:i for i,ch in enumerate(chars)}   \n",
        "ix_to_char = {i:ch for i,ch in enumerate(chars)}    \n",
        "data = data.split('\\n')\n",
        "print(data)\n",
        "print(list(data[0]))\n",
        "random.shuffle(data)"
      ],
      "metadata": {
        "id": "SJ65lqYN_Ibb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.input_size = input_size \n",
        "        self.output_size = input_size \n",
        "\n",
        "        self.rnn = nn.GRU(input_size,hidden_size)\n",
        "        self.h2o = nn.Linear(hidden_size, input_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "\n",
        "        output,hidden=self.rnn(input,hidden)\n",
        "        output=self.h2o(output)\n",
        "        return hidden , output "
      ],
      "metadata": {
        "id": "6zrSiF_M_Kbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "\n",
        "model = RNN(input_size=chars_size, hidden_size=100)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "zd4njL7x_M_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_of_epochs=30\n",
        "hidden_size=100\n",
        "loss=[]\n",
        "for i in range(no_of_epochs):\n",
        "    epoch_loss = 0\n",
        "    n = 0\n",
        "    for word in data:\n",
        "        letters=list(word)\n",
        "        hidden=torch.zeros([1,1,hidden_size])\n",
        "        outputs=torch.zeros([len(letters)+1,chars_size])\n",
        "        target=list()\n",
        "        for c in letters:\n",
        "          target.append(char_to_ix[c])\n",
        "        target.append(char_to_ix['_'])\n",
        "        target_tensor=torch.LongTensor(target)\n",
        "        outputs[0,char_to_ix[letters[0]]]=1\n",
        "        i=0\n",
        "        batch_loss=0\n",
        "        while(i<len(letters)):\n",
        "          input=torch.zeros([1,chars_size],dtype=torch.float)\n",
        "          input[0,char_to_ix[letters[i]]]=1\n",
        "          input=input.unsqueeze(1)\n",
        "          hidden,output=model(input,hidden)\n",
        "          outputs[i+1]=output\n",
        "          i+=1\n",
        "        batch_loss=criterion(outputs,target_tensor)\n",
        "        epoch_loss+=batch_loss\n",
        "        optimizer.zero_grad()\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "        n+=1\n",
        "    epoch_loss=epoch_loss/n\n",
        "    print(epoch_loss.item())\n",
        "    loss.append(epoch_loss.item())"
      ],
      "metadata": {
        "id": "Gk8pfq3f_PUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "hidden_size = 100\n",
        "for letter in chars:\n",
        "    if(letter!=\"_\"):\n",
        "      print(letter,\"-\",end=\"\")\n",
        "      print(letter,end=\"\")\n",
        "      char = letter\n",
        "      input_idx = char_to_ix[char]\n",
        "      input = torch.zeros([1, chars_size], dtype=torch.float)\n",
        "      input[0, input_idx] = 1\n",
        "      input=input.unsqueeze(1)\n",
        "      \n",
        "\n",
        "      hidden = torch.zeros([1, 1,hidden_size])\n",
        "      idx = torch.tensor(char_to_ix[letter])\n",
        "      i=0\n",
        "      while ix_to_char[idx.item()] != \"_\":\n",
        "          i+=1\n",
        "          hidden, output = model(input, hidden)\n",
        "          idx = output.argmax()\n",
        "          input = torch.zeros([1, chars_size], dtype=torch.float)\n",
        "          input[0, idx] = 1\n",
        "          input=input.unsqueeze(1)\n",
        "          if(ix_to_char[idx.item()]!=\"_\"):\n",
        "            print(ix_to_char[idx.item()],end=\"\")\n",
        "      print(\"\")"
      ],
      "metadata": {
        "id": "WyX17Q2Z_ROI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title(\"GRU\")\n",
        "plt.xlabel(\"Number of Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.plot(loss, label = \"Training Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z8cApOra_U67"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}